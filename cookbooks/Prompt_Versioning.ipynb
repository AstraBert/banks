{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTucJvi7Xor_"
      },
      "outputs": [],
      "source": [
        "!pip install banks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"templates\")"
      ],
      "metadata": {
        "id": "iCSH4kOaczt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from banks import Prompt\n",
        "from banks.registries import DirectoryTemplateRegistry\n",
        "\n",
        "# Tell the registry where to store the prompt texts\n",
        "registry = DirectoryTemplateRegistry(Path(\".\") / \"templates\")\n",
        "\n",
        "# Write two versions of the same prompt, optimized for different LLMs\n",
        "blog_prompt_gpt = Prompt(\"Write a 500-word blog post on {{ topic }}.\\n\\nBlog post:\")\n",
        "blog_prompt_llama3 = Prompt(\n",
        "    \"Write a blog post abot the topic {{ topic }}. Do not write more than 500 words\"\n",
        "    \"Examples:\"\n",
        "    \"{% for example in examples %}\"\n",
        "    \"{{ example }}\"\n",
        "    \"{% endfor %}\"\n",
        "    \"\\n\\nBlog post:\"\n",
        ")\n",
        "\n",
        "# Store the two versions under the same name, using the `version` property to\n",
        "# tell them apart.\n",
        "registry.set(name=\"blog_prompt\", prompt=blog_prompt_gpt, version=\"gpt-3.5-turbo\")\n",
        "registry.set(name=\"blog_prompt\", prompt=blog_prompt_llama3, version=\"ollama/llama3.1:8b\")"
      ],
      "metadata": {
        "id": "UaSSFjnUXzMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from litellm import completion\n",
        "from banks.registries import DirectoryTemplateRegistry\n",
        "\n",
        "\n",
        "## set ENV variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
        "\n",
        "# Tell the registry where to store the prompt texts\n",
        "registry = DirectoryTemplateRegistry(Path(\".\") / \"templates\")\n",
        "\n",
        "\n",
        "response = completion(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{ \"content\": registry.get(name=\"blog_prompt\", version=\"gpt-3.5-turbo\").text(), \"role\": \"user\"}]\n",
        ")"
      ],
      "metadata": {
        "id": "IyVpMFN7dAhW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
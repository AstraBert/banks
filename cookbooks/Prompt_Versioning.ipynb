{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt versioning\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/masci/banks/blob/main/cookbooks/Prompt_Versioning.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTucJvi7Xor_"
      },
      "outputs": [],
      "source": [
        "!pip install banks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCSH4kOaczt5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"templates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaSSFjnUXzMD"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from banks import Prompt\n",
        "from banks.registries import DirectoryTemplateRegistry\n",
        "\n",
        "# Tell the registry where to store the prompt texts\n",
        "registry = DirectoryTemplateRegistry(Path(\".\") / \"templates\")\n",
        "\n",
        "# Write two versions of the same prompt, optimized for different LLMs\n",
        "blog_prompt_gpt = Prompt(\"Write a 500-word blog post on {{ topic }}.\\n\\nBlog post:\")\n",
        "blog_prompt_llama3 = Prompt(\n",
        "    \"Write a blog post abot the topic {{ topic }}. Do not write more than 500 words\"\n",
        "    \"Examples:\"\n",
        "    \"{% for example in examples %}\"\n",
        "    \"{{ example }}\"\n",
        "    \"{% endfor %}\"\n",
        "    \"\\n\\nBlog post:\"\n",
        ")\n",
        "\n",
        "# Store the two versions under the same name, using the `version` property to\n",
        "# tell them apart.\n",
        "registry.set(name=\"blog_prompt\", prompt=blog_prompt_gpt, version=\"gpt-3.5-turbo\")\n",
        "registry.set(name=\"blog_prompt\", prompt=blog_prompt_llama3, version=\"ollama/llama3.1:8b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyVpMFN7dAhW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from litellm import completion\n",
        "from banks.registries import DirectoryTemplateRegistry\n",
        "\n",
        "\n",
        "## set ENV variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
        "\n",
        "# Tell the registry where to store the prompt texts\n",
        "registry = DirectoryTemplateRegistry(Path(\".\") / \"templates\")\n",
        "\n",
        "\n",
        "response = completion(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"content\": registry.get(name=\"blog_prompt\", version=\"gpt-3.5-turbo\").text(), \"role\": \"user\"}],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
